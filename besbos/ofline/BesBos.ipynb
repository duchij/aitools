{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d4022f-5ad6-45d9-8fb0-4d0772715b72",
   "metadata": {},
   "source": [
    "# Python Verification scripts\n",
    "- All scripts here are used for local verification\n",
    "- It serves also as demonstration that a model can be learned in the cloud based enviroment and used elsewhere\n",
    "- This script mut be adapated to your local paths were the images/scans are located\n",
    "- All notebooks are written in Python, and use Jupyter project - https://jupyter.org/\n",
    "- These notebooks can be used in Linux, Windows, MacOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea695f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# this enables Intellisense functionality\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6d2cf",
   "metadata": {},
   "source": [
    "# Verification Sigmoid/Binary Classification analysis BesBos\n",
    "- This is verification script for the binary classification\n",
    "- It just predict how much the class is a bonescan or a besilesomab scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# we get all the files for verification\n",
    "testPath = '/PATH/TO/TESTING/FILES'\n",
    "model_path = '/PATH/TO/MODEL/MODEL.keras' #there is also h5 model, but the newest tensorflow forces you to use the keras type\n",
    "pathFile = '{}/{}'\n",
    "\n",
    "files = os.listdir(testPath);\n",
    "print(files)\n",
    "\n",
    "#we load the model we have trained in Google Colab\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "# Classes we want to detect\n",
    "class_names=['bes','bos']\n",
    "#we define the result as two dimensional array of strings\n",
    "result = np.empty(shape=(len(files),2),dtype=object)\n",
    "\n",
    "#method to handle the image and then predict it what it is\n",
    "def predictImage(fileName,index):\n",
    "  img = tf.keras.preprocessing.image.load_img(fileName, target_size=(900,252))\n",
    "  # just plot the image under prediction so it can be also visually analyzed\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  plt.imshow(img)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  #load image as array\n",
    "  Y = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  #expand the information into one dimensional array for prediction\n",
    "  X = np.expand_dims(Y,axis=0)\n",
    "  #predict/infer the loaded image\n",
    "  val1 = model.predict(X)\n",
    "  print(\"prediction tensor\",val1)\n",
    "  score = float(tf.nn.sigmoid(val1[0][0]))\n",
    "  print(\"score sigmoid\", score)\n",
    "  print(f\"This image {fileName} is {100 * (1 - score):.2f}% besilesomab and {100 * score:.2f}% bonescan.\")\n",
    "  print(f\"class:{(class_names[np.argmax(score)])}, {100 * np.max(score)}\")\n",
    "  #we put all results in the list\n",
    "  result[index]=[fileName,f\"{100 * (1 - score):.2f}% / {100 * score:.2f}%\"]\n",
    "\n",
    "\n",
    "index = 0\n",
    "#iteration over the files\n",
    "for file in files:\n",
    "    finalFile = pathFile.format(testPath,file)\n",
    "    #here we take the image, preprocess it into tensor which can be infered by the learned model\n",
    "    predictImage(finalFile,index)\n",
    "    index +=1\n",
    "print(\"Final result table:\")\n",
    "#print out the list can be copied into Excel\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc20bd-6465-4514-a374-3b261e59683a",
   "metadata": {},
   "source": [
    "# Verification script for multiclass image classification\n",
    "- predicts the proabability of the distribution among our 4 classes\n",
    "- create a directory with all the not trained images\n",
    "- each scan is printed out and under it is the tensor with the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f2256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "%config IPCompleter.greedy=True\n",
    "#from where to load the images\n",
    "testPath = Path('PATH/TO/THE/FOLDER/WITH_MULTICLASS_DATASET')\n",
    "#classes to be infered\n",
    "class_names=['besnegat','besposit','bosnegat','bosposit']\n",
    "#path to the model to use \n",
    "model_path = Path(\"/PATH_TO_PATH/WITH_THE_MODEL/MODEL_NAME.keras\")\n",
    "#form teaplte to create the dynamic path to files\n",
    "pathFile = '{}/{}'\n",
    "#loading the model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "files = os.listdir(testPath);\n",
    "print(files)\n",
    "\n",
    "#creating the empty list\n",
    "result = np.empty(shape=(len(files),2),dtype=object)\n",
    "\n",
    "\n",
    "def predictImage(fileName,index):\n",
    "  img = tf.keras.preprocessing.image.load_img(fileName, target_size=(900,252))\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  plt.imshow(img)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  Y = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  X = np.expand_dims(Y,axis=0)\n",
    "  #tensor of prediction\n",
    "  val1 = model.predict(X)\n",
    "  print(\"prediction tensor:\",val1)\n",
    "  #softamx calculates the probability distribution among the results creating another tensor with final results\n",
    "  score2 = tf.nn.softmax(val1[0])\n",
    "  print(\"score softmax\", score2)\n",
    "  print(f\"{fileName} class:{(class_names[np.argmax(score2)])}, {100 * np.max(score2)}\")\n",
    "  #we add all to the list\n",
    "  result[index]=[fileName,f\"{(class_names[np.argmax(score2)])}, {100 * np.max(score2)}\"]\n",
    "#loading all files from the directory\n",
    "\n",
    "index = 0\n",
    "for file in files:\n",
    "    finalFile = f\"{testPath}/{file}\"\n",
    "    predictImage(finalFile,index)\n",
    "    index +=1\n",
    "print(\"Final results\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e25283-df5d-4ab8-9364-676edbf8af72",
   "metadata": {},
   "source": [
    "# Correctly Resize the image and rotate it based on the EXIF tag\n",
    "- this script serves as a helping tool in case of using to predict an image from a monitor screen taken by mobile camera\n",
    "- resizes the image\n",
    "- checks EXIF information -> correct angle of rotation\n",
    "- adapts resize filter -> Bicubic, can be change to any filter eg. Lancoz\n",
    "- The result is an image of the correct size, moire noise is lowered so the prediction is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7680ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "from PIL.ExifTags import Base\n",
    "model_width = 252\n",
    "model_height = 900\n",
    "\n",
    "TESTFILE = \"PATH_TO_THE_FILES_TO_CORRECT\"\n",
    "\n",
    "def resize_image(image):\n",
    "    i_width, i_height = image.size\n",
    "    exif = image.getexif()\n",
    "  \n",
    "    if 274 in exif:\n",
    "        rotate = True     \n",
    "    else:\n",
    "        rotate = False\n",
    "        \n",
    "    print(\"Exif tag:\",Base(274).name)\n",
    "    percentage_h = model_height / i_height\n",
    "    percentage_w = model_width / i_width\n",
    "    \n",
    "    new_width = int(i_width * percentage_w)\n",
    "    new_height = int(i_height * percentage_h)\n",
    "    print(\"New Size\", new_width, new_height)\n",
    "    if rotate:\n",
    "        if exif[274] == 6:\n",
    "            image = image.rotate(-90,expand=1)\n",
    "        if exif[274] == 8:\n",
    "            image = image.rotate(90,expand=1)\n",
    "    image = image.resize((new_width, new_height), Image.Resampling.BICUBIC)\n",
    "    return image.filter(ImageFilter.BLUR)\n",
    "\n",
    "pathFile = '{}/{}'\n",
    "if __name__ == \"__main__\":\n",
    "  file_name = sys.argv[1]\n",
    "  identifier = sys.argv[2]\n",
    "  extension = sys.argv[3]\n",
    "finalFile = pathFile.format(TESTFILE,file_name)\n",
    "image = Image.open(finalFile)\n",
    "new_image = resize_image(image)\n",
    "\n",
    "save_file_tpl = \"{}/final_{}.{}\"\n",
    "finalSave = save_file_tpl.format(TESTFILE,identifier,extension)\n",
    "n_image.save(finalSave)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97fbf9",
   "metadata": {},
   "source": [
    "# Color channel harmonization\n",
    "- takes a grayscale image with one color channel and makes it an RGB grayscale image with three channels\n",
    "- in short, it just copies the one channel into the two remaining, for a grayscale image it does not compose a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "testPath = '/PATH/TO/THE/FILES/'\n",
    "outPath = '/PATH/TO/THE/SAVE_FILES/'\n",
    "class_names = [\"besnegat\",\"besposit\",\"bosnegat\",\"bosposit\"]\n",
    "main_path = '/PATH/TO/THE/FILES/'\n",
    "\n",
    "def expand_greyscale_image_channels(grey_pil_image):\n",
    "    grey_image_arr = np.asarray(grey_pil_image)\n",
    "    print(\"one array\", grey_image_arr.shape)\n",
    "    #print(\"shape[2]==3\",grey_image_arr.shape[2])\n",
    "    if len(grey_image_arr.shape) == 3 and grey_image_arr.shape[2]==3:\n",
    "        print(\"image has 3 channels\")\n",
    "    elif len(grey_image_arr.shape) == 2:\n",
    "        print(\"Image is one channel, adapting\")\n",
    "        grey_image_arr = np.expand_dims(grey_image_arr, -1)\n",
    "        #just simply adding the same one channel to all other channels\n",
    "        grey_image_arr_3_channel = grey_image_arr.repeat(3, axis=-1)\n",
    "        return Image.fromarray(grey_image_arr_3_channel.astype('uint8'),'RGB')\n",
    "    else:\n",
    "        print(\"Image has unknown channels\")\n",
    "        \n",
    "    return Image.fromarray(grey_image_arr.astype('uint8'),'RGB')\n",
    "\n",
    "for item in class_names:\n",
    "    path =f\"{main_path}/{item}/\"\n",
    "    print(\"class-\",item)\n",
    "    files = os.listdir(path);\n",
    "    for file in files:\n",
    "        print(\"file to change:\",file)\n",
    "        img = Image.open(f\"{path}/{file}\")\n",
    "        img2 = expand_greyscale_image_channels(img)\n",
    "        img2.save(f\"{outPath}/{item}/{file}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc85122-44ac-4767-a0ab-4aa98566eb51",
   "metadata": {},
   "source": [
    "# Pre-training augmentation\n",
    "- the image is vertically flipped and saved\n",
    "- this is a part of augmentation technique to control the amount of data in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "\n",
    "PATH = 'PATH/TO/FILES/FOR/EACH/CLASS'\n",
    "PATH_TO_CLASS = \"/OUTPUT_PATH/TO/SAVE\"\n",
    "files = os.listdir(PATH)\n",
    "filesCount = len(files)\n",
    "#this will flip or enhance contrast a larger dataset can be created and insereted into learning\n",
    "index = 1\n",
    "for index in range(1,3):\n",
    "    for file in files:\n",
    "        if index == 1:\n",
    "            img = Image.open(f\"{PATH}{file}\")\n",
    "            imgFlip = img.transpose(Image.ROTATE_180)\n",
    "            imgFlip.save(f\"{PATH}f_{file}\")\n",
    "            print(\"Flipped image:f_\",file);\n",
    "        if index == 3:\n",
    "            img = Image.open(f\"{PATH_TO_CLASS\"/{file}\")\n",
    "            imgE = ImageEnhance.Contrast(img)\n",
    "            img_final = imgE.enhance(2.5)\n",
    "            img_final.save(f\"{PATH_TO_CLASS}/c_{file}\")\n",
    "            print(\"Contrasted image:c_\",file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b6ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
